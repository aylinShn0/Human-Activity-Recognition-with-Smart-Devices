{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332bfc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, ConfusionMatrixDisplay\n",
    "\n",
    "data = pd.read_csv('dataset/KU-HAR/3.Time_domain_subsamples/KU-HAR_time_domain_subsamples_subset.csv', header=None)\n",
    "activity_labels = [\n",
    "    'Stand',\n",
    "    'Sit',\n",
    "    'Talk-sit',\n",
    "    'Talk-stand',\n",
    "    'Stand-sit',\n",
    "    'Lay',\n",
    "    'Lay-stand',\n",
    "    'Pick',\n",
    "    'Jump',\n",
    "    'Push-up',\n",
    "    'Sit-up',\n",
    "    'Walk',\n",
    "    'Walk-backward',\n",
    "    'Walk-circle',\n",
    "    'Run',\n",
    "    'Stair-up',\n",
    "    'Stair-down',\n",
    "    'Table-tennis'\n",
    "]\n",
    "#print(data.head())\n",
    "sensor_data = data.iloc[:, :1800].to_numpy()\n",
    "labels = data.iloc[:,1800].to_numpy()\n",
    "#(sensor_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a733d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_index = [\n",
    "    (0, 300),    #acc_x\n",
    "    (300, 600),   #acc_y\n",
    "    (600, 900),   #acc_z\n",
    "    (900, 1200),  #gyro_x\n",
    "    (1200, 1500), #gyro_y\n",
    "    (1500, 1800)  #gyro_z\n",
    "]\n",
    "\n",
    "feature_list = []\n",
    "\n",
    "for i in range(sensor_data.shape[0]):\n",
    "    segment_row = sensor_data[i]\n",
    "    segment_features = []\n",
    "    for j in range(len(sensor_index)):\n",
    "        start, end = sensor_index[j]\n",
    "        data = segment_row[start:end]\n",
    "\n",
    "        segment_features.append(np.mean(data))\n",
    "        segment_features.append(np.min(data))\n",
    "        segment_features.append(np.max(data))\n",
    "        segment_features.append(np.std(data))\n",
    "        segment_features.append(np.median(data))\n",
    "        segment_features.append(stats.median_abs_deviation(data)) # mad\n",
    "        segment_features.append(np.sqrt(np.mean(data**2))) # rms\n",
    "        segment_features.append(np.sum(data**2)) # enerji\n",
    "        \n",
    "        hist, _ = np.histogram(data, bins=10, density=True)\n",
    "        segment_features.append(stats.entropy(hist))  # entropi\n",
    "\n",
    "    feature_list.append(segment_features)\n",
    "\n",
    "feature_extraction = pd.DataFrame(feature_list)\n",
    "feature_names = ['mean', 'min', 'max', 'std', 'median', 'mad', 'rms', 'energy', 'entropy']\n",
    "axis_name = ['acc_x', 'acc_y', 'acc_z', 'gyro_x', 'gyro_y', 'gyro_z']\n",
    "\n",
    "column_names = [f'{axis}_{feat}' for axis in axis_name for feat in feature_names]\n",
    "feature_extraction.columns = column_names\n",
    "y_labels = labels\n",
    "\n",
    "# print(feature_extraction.shape)\n",
    "# print(feature_extraction.head())\n",
    "#print(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1133f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, Y_Tesst = train_test_split(feature_extraction, y_labels, test_size=0.3, random_state=42,stratify =y_labels)\n",
    "\n",
    "scaler = joblib.load('models/kuhar/standard_scaler.joblib')\n",
    "pca = joblib.load('models/kuhar/pca_transformer.joblib')\n",
    "\n",
    "#StandardScaler (SVM, KNN, MLP)\n",
    "x_test_scaled=scaler.transform(x_test)\n",
    "\n",
    "#PCA\n",
    "x_test_pca=pca.transform(x_test)\n",
    "x_test_scaled_pca = pca.transform(x_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5451bbae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 8 features, but KNeighborsClassifier is expecting 9 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     40\u001b[39m         X_test = x_test\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_Tesst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, X_test, y_test, name)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate_model\u001b[39m(model, X_test, y_test, name):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     y_pred = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m     accuracy = accuracy_score(y_test, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aylin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:274\u001b[39m, in \u001b[36mKNeighborsClassifier.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    271\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.classes_[np.argmax(probabilities, axis=\u001b[32m1\u001b[39m)]\n\u001b[32m    272\u001b[39m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[32m    273\u001b[39m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m274\u001b[39m     neigh_ind = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m     neigh_dist = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aylin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:838\u001b[39m, in \u001b[36mKNeighborsMixin.kneighbors\u001b[39m\u001b[34m(self, X, n_neighbors, return_distance)\u001b[39m\n\u001b[32m    836\u001b[39m         X = _check_precomputed(X)\n\u001b[32m    837\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m838\u001b[39m         X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m            \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m            \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m            \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    847\u001b[39m n_samples_fit = \u001b[38;5;28mself\u001b[39m.n_samples_fit_\n\u001b[32m    848\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors > n_samples_fit:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aylin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2975\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2972\u001b[39m     out = X, y\n\u001b[32m   2974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m2975\u001b[39m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2977\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\aylin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2839\u001b[39m, in \u001b[36m_check_n_features\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2836\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   2838\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_features != estimator.n_features_in_:\n\u001b[32m-> \u001b[39m\u001b[32m2839\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2840\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2841\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator.n_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m features as input.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2842\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: X has 8 features, but KNeighborsClassifier is expecting 9 features as input."
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_test, y_test, name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\n Model: {name}\")\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=activity_labels, zero_division=0))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    figure, axes = plt.subplots(figsize=(15,15))\n",
    "    ConfusionMatrixDisplay.from_estimator(\n",
    "        model,\n",
    "        X_test,\n",
    "        y_test,\n",
    "        display_labels=activity_labels,\n",
    "        cmap='Greens',  \n",
    "        xticks_rotation='vertical', \n",
    "        ax=axes \n",
    "    )\n",
    "    plt.title(name)\n",
    "    plt.show()\n",
    "\n",
    "model_dir = 'models/kuhar'\n",
    "for file in sorted(os.listdir(model_dir)):\n",
    "    if file.endswith('.joblib'):\n",
    "        model = joblib.load(os.path.join(model_dir, file))\n",
    "        file_lower = file.lower()\n",
    "        if 'with_pca' in file_lower:\n",
    "            if any(x in file_lower for x in ['svm', 'knn', 'mlp']):\n",
    "                X_test = x_test_scaled_pca\n",
    "            else:\n",
    "                X_test = x_test_pca\n",
    "        elif 'hp_optimization' in file_lower:\n",
    "            if any(x in file_lower for x in ['svm', 'knn', 'mlp']):\n",
    "                X_test = x_test_scaled_pca\n",
    "            else:\n",
    "                X_test = x_test_pca\n",
    "        else:  # without pca\n",
    "            if any(x in file_lower for x in ['svm', 'knn', 'mlp']):\n",
    "                X_test = x_test_scaled\n",
    "            else:\n",
    "                X_test = x_test\n",
    "\n",
    "        evaluate_model(model, X_test, Y_Tesst, name=file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
