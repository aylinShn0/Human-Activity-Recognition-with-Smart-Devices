{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "756922b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aylin\\AppData\\Local\\Temp\\ipykernel_16628\\860129956.py:15: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  raw_data.interpolate(method='linear', limit_direction ='both', inplace=True) # eksik veri tamamlandı\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, ConfusionMatrixDisplay\n",
    "\n",
    "cols = ['user', 'activity', 'timestamp', 'x-accel', 'y-accel', 'z-accel']\n",
    "raw_data = pd.read_csv('dataset/wisdm/WISDM_ar_v1.1/WISDM_ar_v1.1_raw.txt', header=None,names=cols, sep=\",\",on_bad_lines='skip')\n",
    "raw_data['z-accel'] = raw_data['z-accel'].str.replace(';', '').astype(float)\n",
    "raw_data.interpolate(method='linear', limit_direction ='both', inplace=True) # eksik veri tamamlandı\n",
    "\n",
    "#print(raw_data.head())\n",
    "\n",
    "#Aktivite ve Kodları:\n",
    "# 0: Downstairs\n",
    "# 1: Jogging\n",
    "# 2: Sitting\n",
    "# 3: Standing\n",
    "# 4: Upstairs\n",
    "# 5: Walking\n",
    "raw_data['actvity_code'] = raw_data['activity'].astype('category').cat.codes\n",
    "work_data = raw_data[['user','actvity_code','timestamp', 'x-accel', 'y-accel', 'z-accel']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1dbaea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_frequency = 20\n",
    "seconds=3\n",
    "window_size = seconds * sample_frequency #20Hz 3 seconds 20*3=60\n",
    "feature_count = 3 #x,y,z\n",
    "step = window_size # for non-overlap segments\n",
    "\n",
    "segments = []\n",
    "labels = []\n",
    "\n",
    "data_for_segmentation = work_data[['x-accel', 'y-accel', 'z-accel']].values\n",
    "labels_for_segmentation = work_data['actvity_code'].values\n",
    "\n",
    "for user in work_data['user'].unique():\n",
    "    for act_code in work_data['actvity_code'].unique():\n",
    "        s_index = work_data.index[(work_data['user'] == user) & (work_data['actvity_code'] == act_code)].tolist()\n",
    "        for i in range(0, len(s_index) - window_size, step):\n",
    "            window_start = s_index[i]\n",
    "            window_end = window_start + window_size\n",
    "            \n",
    "            segment = data_for_segmentation[window_start : window_end]\n",
    "            label = stats.mode(labels_for_segmentation[window_start : window_end], keepdims=True).mode[0]\n",
    "            \n",
    "            segments.append(segment)\n",
    "            labels.append(label)\n",
    "\n",
    "reshaped_segments = np.asarray(segments, dtype=np.float32)\n",
    "labels = np.asarray(labels)\n",
    "#print(reshaped_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c5e974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = []\n",
    "\n",
    "for i in range(reshaped_segments.shape[0]): #bütün segmentler, 18bin tane yklşk\n",
    "    segment = reshaped_segments[i]\n",
    "    segment_features = []\n",
    "    \n",
    "    for j in range(segment.shape[1]): #3 ekseni dön, xyz\n",
    "        data = segment[:, j]\n",
    "        segment_features.append(np.mean(data))\n",
    "        segment_features.append(np.min(data))\n",
    "        segment_features.append(np.max(data))\n",
    "        segment_features.append(np.std(data))\n",
    "        segment_features.append(np.median(data))\n",
    "        segment_features.append(stats.median_abs_deviation(data)) #mad\n",
    "        segment_features.append(np.sqrt(np.mean(data**2))) #rsm\n",
    "        segment_features.append(np.sum(data**2)) #enerji - jog/walk yüksek enerji, sit/stand düşük enerji\n",
    "        \n",
    "        hist, _ = np.histogram(data, bins=10, density=True)\n",
    "        segment_features.append(stats.entropy(hist))  #entropi\n",
    "\n",
    "    feature_list.append(segment_features)\n",
    "    \n",
    "#print(len(feature_list))\n",
    "#print(feature_list[0])\n",
    "#print(feature_list[1])\n",
    "feature_extraction = pd.DataFrame(feature_list)\n",
    "\n",
    "feature_names = ['mean', 'min', 'max', 'std', 'median', 'mad', 'rms', 'energy', 'entropy']\n",
    "axis_name = ['x', 'y', 'z']\n",
    "column_names = [f'{axis}_{feat}' for axis in axis_name for feat in feature_names ]\n",
    "feature_extraction.columns = column_names\n",
    "y_labels = labels.ravel()\n",
    "\n",
    "#print(feature_extraction.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ec8c2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aylin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2742: UserWarning: X has feature names, but PCA was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(feature_extraction, y_labels, test_size=0.3, random_state=42,stratify =y_labels)\n",
    "\n",
    "scaler = joblib.load('models/wisdm/standard_scaler.joblib')\n",
    "pca = joblib.load('models/wisdm/pca_transformer.joblib')\n",
    "\n",
    "#StandardScaler (SVM, KNN, MLP)\n",
    "x_test_scaled=scaler.transform(x_test)\n",
    "\n",
    "#PCA\n",
    "x_test_pca=pca.transform(x_test)\n",
    "x_text_scaled_pca = pca.transform(x_test_scaled)\n",
    "\n",
    "activity_labels = list(raw_data['activity'].astype('category').cat.categories)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cedf7be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Model: KNN_With_PCA_kuhar.joblib\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 10 features, but KNeighborsClassifier is expecting 9 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         X_test \u001b[38;5;241m=\u001b[39m x_test\n\u001b[1;32m---> 41\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, X_test, y_test, name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate_model\u001b[39m(model, X_test, y_test, name):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aylin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:274\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(probabilities, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\aylin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_base.py:838\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    836\u001b[0m         X \u001b[38;5;241m=\u001b[39m _check_precomputed(X)\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 838\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m            \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[43m            \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    844\u001b[0m \u001b[43m            \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    847\u001b[0m n_samples_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_fit_\n\u001b[0;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;241m>\u001b[39m n_samples_fit:\n",
      "File \u001b[1;32mc:\\Users\\aylin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2975\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2972\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2974\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m-> 2975\u001b[0m     \u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2977\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\aylin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2839\u001b[0m, in \u001b[0;36m_check_n_features\u001b[1;34m(estimator, X, reset)\u001b[0m\n\u001b[0;32m   2836\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m estimator\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m-> 2839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2840\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2841\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2842\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 10 features, but KNeighborsClassifier is expecting 9 features as input."
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X_test, y_test, name):\n",
    "    print(f\"\\n Model: {name}\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "    print(classification_report(y_test, y_pred, target_names=activity_labels, zero_division=0))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    figure, axes = plt.subplots(figsize=(15,15))\n",
    "    ConfusionMatrixDisplay.from_predictions(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        display_labels=activity_labels,\n",
    "        cmap='Greens',  \n",
    "        xticks_rotation='horizontal', \n",
    "        ax=axes \n",
    "    )\n",
    "    plt.title(name)\n",
    "    plt.show()\n",
    "\n",
    "model_dir = 'models/kuhar'\n",
    "for file in sorted(os.listdir(model_dir)):\n",
    "    if file.endswith('.joblib'):\n",
    "        model = joblib.load(os.path.join(model_dir, file))\n",
    "        file_lower = file.lower()\n",
    "        if 'with_pca' in file_lower:\n",
    "            if any(x in file_lower for x in ['svm', 'knn', 'mlp']):\n",
    "                X_test = x_text_scaled_pca\n",
    "            else:\n",
    "                X_test = x_test_pca\n",
    "        elif 'hp_optimization' in file_lower:\n",
    "            if any(x in file_lower for x in ['svm', 'knn', 'mlp']):\n",
    "                X_test = x_text_scaled_pca\n",
    "            else:\n",
    "                X_test = x_test_pca\n",
    "        else:  # without pca\n",
    "            if any(x in file_lower for x in ['svm', 'knn', 'mlp']):\n",
    "                X_test = x_test_scaled\n",
    "            else:\n",
    "                X_test = x_test\n",
    "\n",
    "        evaluate_model(model, X_test, y_test, name=file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
